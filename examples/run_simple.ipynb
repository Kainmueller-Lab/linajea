{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0754861b",
   "metadata": {},
   "source": [
    "Linajea Tracking Example\n",
    "=====================\n",
    "\n",
    "This example show all steps necessary to generate the final tracks, from training the network to finding the optimal ILP weights on the validation data to computing the tracks on the test data.\n",
    "\n",
    "- train network\n",
    "- predict on validation data\n",
    "- grid search weights for ILP\n",
    "  - solve once per set of weights\n",
    "  - evaluate once per set of weights\n",
    "  - select set with fewest errors\n",
    "- predict on test data\n",
    "- solve on test data with optimal weights\n",
    "- evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from linajea.config import TrackingConfig\n",
    "import linajea.evaluation\n",
    "from linajea.process_blockwise import (extract_edges_blockwise,\n",
    "                                       predict_blockwise,\n",
    "                                       solve_blockwise)\n",
    "from linajea.training import train\n",
    "import linajea.config\n",
    "import linajea.process_blockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(name)s %(levelname)-8s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2706",
   "metadata": {},
   "source": [
    "Configuration\n",
    "--------------------\n",
    "\n",
    "All parameters to control the pipeline (e.g. model architecture, data augmentation, training parameters, ILP weights) are contained in a configuration file (in the TOML format https://toml.io)\n",
    "\n",
    "You can use a single monolithic configuration file or separate configuration files for a subset of the steps of the pipeline, as long as the parameters required for the respective steps are there.\n",
    "\n",
    "Familiarize yourself with the example configuration files and have a look at the documentation for the configuration to see what is needed. Most parameters have sensible defaults; usually setting the correct paths and the data configuration is all that is needed to start. See `run_advanced.ipynb` for an example setup that can (optionally) handle multiple samples and automates the process of selecting the correct data for each step as much as possible.\n",
    "\n",
    "In this setup for training `train_data` has to be set, and for validation and testing `inference_data`.\n",
    "\n",
    "\n",
    "Experiment\n",
    "-----------------\n",
    "\n",
    "To start a new experiment create a new folder and copy the configuration file(s) you want to use into this folder.\n",
    "Then modify the `config_file` variable to point to the config file. Make sure that the file paths contained in it point to the correct destination, for instance that they are adapted to your directory structure. And that `config.general.setup_dir` points to the folder you just created. \n",
    "To continue an existing experiment simply set `config_file` to point to the existing config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ca24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dir = \"example_simple_1\"\n",
    "os.chdir(setup_dir)\n",
    "train_config_file = \"config_example_minimal.toml\"\n",
    "train_config = TrackingConfig.from_file(train_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4a402",
   "metadata": {},
   "source": [
    "Training\n",
    "------------\n",
    "\n",
    "To start training simply pass the configuration object to the train function. Make sure that the training data and parameters such as the number of iterations/setps are set correctly.\n",
    "\n",
    "To train until convergence will take from several hours to multiple days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done in child process to automatically free cuda resources\n",
    "p = multiprocessing.Process(target=train, args=(train_config,))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c022b",
   "metadata": {},
   "source": [
    "Validation\n",
    "--------------\n",
    "\n",
    "After the training is completed we first have to determine the optimal ILP weights.\n",
    "This is achieved by first creating the prediction on the validation data and then performing a grid search by solving the ILP and evaluating the results repeatedly.\n",
    "\n",
    "MongoDB is used to store the computed results. A `mongod` server has to be running before executing the remaining cells.\n",
    "See https://www.mongodb.com/docs/manual/administration/install-community/ for a guide on how to install it (Linux/Windows/MacOS)\n",
    "Alternatively you might want to create a singularity image (https://github.com/singularityhub/mongo). This can be used locally but will be necessary if you want to run the code on an HPC cluster and there is no server installed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_config_file = \"config_example_val_minimal.toml\"\n",
    "val_config = TrackingConfig.from_file(validation_config_file)\n",
    "os.makedirs(val_config.general.setup_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240c93",
   "metadata": {},
   "source": [
    "### Predict Validation Data\n",
    "\n",
    "First we predict the `cell_indicator` and `movement_vectors` on the validation data. Make sure that `inference_data` in the config file points to the data you want to use for validation. The extracted maxima of the `cell_indicator` map correspond to potential cells in our candidate graph.\n",
    "\n",
    "Depending on the number of workers used (see config file) and the size of the data this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9124e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba90ec2",
   "metadata": {},
   "source": [
    "### Extract Edges Validation Data\n",
    "\n",
    "In the next step we extract potential edges for our candidate graph. For each cell candidate, look for neighboring cells in the next time frame and insert an edge candidate for each into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_edges_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032f671",
   "metadata": {},
   "source": [
    "### ILP Weights Grid Search\n",
    "\n",
    "Cell/Node and edge candidates form together our candidate graph. By solving the ILP we extract tracks from this graph. However the ILP is parameterized by a set of weights. First we have to find the optimal values for these weights. To achieve this we perform a grid search over a predefined search space. For each set of parameter candidates we solve the ILP once on the validation data.\n",
    "\n",
    "#### Solve on Validation Data\n",
    "\n",
    "Make sure to either provide parameter sets yourself (`solve.parameters`) or that `solve.grid_search` is set to `True`. The parameter sets to try are then generated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fc5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linajea.process_blockwise.solve_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a28d14",
   "metadata": {},
   "source": [
    "#### Evaluate on Validation Data\n",
    "\n",
    "And as a last validation step we evaluate the performance for each set of parameter candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_config_file = \"config_example_val_minimal.toml\"\n",
    "val_config = TrackingConfig.from_file(validation_config_file)\n",
    "parameters = val_config.solve.parameters\n",
    "for params in parameters:\n",
    "    val_config.solve.parameters = [params]\n",
    "    linajea.evaluation.evaluate_setup(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4f46b",
   "metadata": {},
   "source": [
    "#### Determine best ILP weights\n",
    "\n",
    "The set of weights/parameters resulting in the best performance (fewest number of errors) will then be used to get the performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = ['fn_edges', 'identity_switches',\n",
    "                 'fp_divisions', 'fn_divisions']\n",
    "if not val_config.general.sparse:\n",
    "    score_columns = ['fp_edges'] + score_columns\n",
    "\n",
    "results = linajea.evaluation.get_results_sorted(\n",
    "    val_config,\n",
    "    filter_params={\"val\": True},\n",
    "    score_columns=score_columns,\n",
    "    sort_by=\"sum_errors\")\n",
    "\n",
    "parameters = val_config.solve.parameters[0]\n",
    "parameters.weight_node_score = float(results.iloc[0].weight_node_score)\n",
    "parameters.selection_constant = float(results.iloc[0].selection_constant)\n",
    "parameters.track_cost = float(results.iloc[0].track_cost)\n",
    "parameters.weight_edge_score = float(results.iloc[0].weight_edge_score)\n",
    "parameters.weight_division = float(results.iloc[0].weight_division)\n",
    "parameters.weight_child = float(results.iloc[0].weight_child)\n",
    "parameters.weight_continuation = float(results.iloc[0].weight_continuation)\n",
    "\n",
    "print(\"Best parameters:\\n\", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c155ee",
   "metadata": {},
   "source": [
    "Test\n",
    "------\n",
    "\n",
    "Now that we know which ILP weights to use we can create the candidate graph on the test data and compute the tracks. \n",
    "\n",
    "First load the test configuration file and set the parameters to the previously determined values (alternatively set the values manually directly in the configuration file). \n",
    "Make sure that `solve.grid_search` and `solve.random_search` are not set or set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dade09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config_file = \"config_example_test_minimal.toml\"\n",
    "test_config = TrackingConfig.from_file(test_config_file)\n",
    "test_config.solve.parameters = [parameters]\n",
    "test_config.solve.solver_type = val_config.solve.solver_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174b602",
   "metadata": {},
   "source": [
    "### Predict Test Data\n",
    "\n",
    "As before we first predict the `cell_indicator` and `movement_vectors`, this time on the test data. Make sure that `inference_data` in the config file points to the data you want to use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73142808",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a4f5c",
   "metadata": {},
   "source": [
    "### Extract Edges on Test Data\n",
    "\n",
    "In the next step we extract again the potential edges for our candidate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d995474",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_edges_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0660d",
   "metadata": {},
   "source": [
    "### Solve on Test Data\n",
    "\n",
    "Then we can solve the ILP on the test data and compute the tracks. Make sure that the ILP weights are set to the values that resulted in the lowest overall number of errors on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a141c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config.solve.from_scratch = True\n",
    "solve_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448cb8d",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data\n",
    "\n",
    "And finally we can evaluate the performance of our tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03698bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = linajea.evaluation.evaluate_setup(test_config)\n",
    "print(report.get_short_report())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:linajea_torch] *",
   "language": "python",
   "name": "conda-env-linajea_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
