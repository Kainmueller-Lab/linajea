{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0754861b",
   "metadata": {},
   "source": [
    "Linajea Tracking Example\n",
    "=====================\n",
    "\n",
    "This example show all steps necessary to generate the final tracks, from training the network to finding the optimal ILP weights on the validation data to computing the tracks on the test data.\n",
    "\n",
    "- train network\n",
    "- predict on validation data\n",
    "- grid search weights for ILP\n",
    "  - solve once per set of weights\n",
    "  - evaluate once per set of weights\n",
    "  - select set with fewest errors\n",
    "- predict on test data\n",
    "- solve on test data with optimal weights\n",
    "- evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from linajea.config import TrackingConfig\n",
    "import linajea.evaluation\n",
    "from linajea.process_blockwise import (extract_edges_blockwise,\n",
    "                                       predict_blockwise,\n",
    "                                       solve_blockwise)\n",
    "from linajea.training import train\n",
    "import linajea.config\n",
    "import linajea.process_blockwise\n",
    "import linajea.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(name)s %(levelname)-8s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17198adc",
   "metadata": {},
   "source": [
    "Experiment\n",
    "-----------------\n",
    "\n",
    "To start a new experiment create a new folder and copy the configuration file(s) you want to use into this folder.\n",
    "For this example we have already done this for you (`example_basic`). Then change the current working directory to that folder.\n",
    "Make sure that the file paths contained in the configuration files point to the correct destination, for instance that they are adapted to your directory structure. And that `config.general.setup_dir` is set to the folder you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dir = \"example_basic\"\n",
    "os.chdir(setup_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb37cd",
   "metadata": {},
   "source": [
    "Setup\n",
    "--------\n",
    "\n",
    "Make sure that the `linajea` package is installed and that the correct kernel is selected in the jupyter notebook.\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "Set `download_data` to `True` and execute the next cell to download a subset of: *3D+time nuclei tracking dataset of confocal fluorescence microscopy time series of C. elegans embryos* (https://zenodo.org/record/6460303).\n",
    "\n",
    "Each sample contains 15 time frames from a developing C. elegans embryo.\n",
    "One sample will be used for training, one for validation and one for testing.\n",
    "You can of course use your own data, it has to be in a compatible format (see https://github.com/funkelab/linajea/examples/README.md for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = False\n",
    "if download_data:\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873672 -N --show-progress\n",
    "    !ln -s 36873672 mskcc_emb1_15fr.zip\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873675 -N --show-progress\n",
    "    !mv 36873675 mskcc_emb1_15fr_tracks.csv\n",
    "\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873723 -N --show-progress\n",
    "    !ln -s 36873723 mskcc_emb2_15fr.zip\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873726 -N --show-progress\n",
    "    !mv 36873726 mskcc_emb3_15fr_tracks.csv\n",
    "\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873825 -N --show-progress\n",
    "    !ln -s 36873825 mskcc_emb3_15fr.zip\n",
    "    !wget -c https://figshare.com/ndownloader/files/36873828 -N --show-progress\n",
    "    !mv 36873828 mskcc_emb3_15fr_tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a3ed9",
   "metadata": {},
   "source": [
    "### Database\n",
    "\n",
    "MongoDB is used to store the computed results. A `mongod` server has to be running before executing the remaining cells.\n",
    "See https://www.mongodb.com/docs/manual/administration/install-community/ for a guide on how to install it (Linux/Windows/MacOS).\n",
    "Alternatively you might want to create a singularity image (https://github.com/singularityhub/mongo). This can be used locally, too, but will be necessary if you want to run the code on an HPC cluster and there is no server installed already.\n",
    "\n",
    "Set `setup_databases` to `True` to add the ground truth tracks to the database server. Make sure to set `db_host` to the correct server (if you run it locally you can usually just set it to `\"localhost\"`). If you use different data you also have to adapt `csv_tracks_file` and `db_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7c568",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "setup_databases = False\n",
    "db_host = \"localhost\"\n",
    "if setup_databases:\n",
    "    csv_tracks_file = \"mskcc_emb1_15fr_tracks.csv\"\n",
    "    db_name = \"linajea_mskcc_emb1_15fr_gt\"\n",
    "    linajea.utils.add_tracks_to_database(\n",
    "        csv_tracks_file,\n",
    "        db_name,\n",
    "        db_host)\n",
    "    \n",
    "    csv_tracks_file = \"mskcc_emb2_15fr_tracks.csv\"\n",
    "    db_name = \"linajea_mskcc_emb2_15fr_gt\"\n",
    "    linajea.utils.add_tracks_to_database(\n",
    "        csv_tracks_file,\n",
    "        db_name,\n",
    "        db_host)\n",
    "    \n",
    "    csv_tracks_file = \"mskcc_emb3_15fr_tracks.csv\"\n",
    "    db_name = \"linajea_mskcc_emb3_15fr_gt\"\n",
    "    linajea.utils.add_tracks_to_database(\n",
    "        csv_tracks_file,\n",
    "        db_name,\n",
    "        db_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2706",
   "metadata": {},
   "source": [
    "Configuration\n",
    "--------------------\n",
    "\n",
    "All parameters to control the pipeline (e.g. model architecture, data augmentation, training parameters, ILP weights) are contained in a configuration file (in the TOML format https://toml.io)\n",
    "\n",
    "You can use a single monolithic configuration file or separate configuration files for a subset of the steps of the pipeline, as long as the parameters required for the respective steps are there.\n",
    "\n",
    "Familiarize yourself with the example configuration files and have a look at the documentation for the configuration to see what is needed. Most parameters have sensible defaults; usually setting the correct paths and the data configuration is all that is needed to start. See `run_advanced.ipynb` for an example setup that can (optionally) handle multiple samples and automates the process of selecting the correct data for each step as much as possible.\n",
    "\n",
    "In this setup for training `train_data` has to be set, and for validation and testing `inference_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4a402",
   "metadata": {},
   "source": [
    "Training\n",
    "------------\n",
    "\n",
    "To start training load the appropriate configuration file and pass the configuration object to the train function. Make sure that the training data and parameters such as the number of iterations/setps are set correctly.\n",
    "\n",
    "To train until convergence will take from several hours to multiple days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab649e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_file = \"config_train.toml\"\n",
    "train_config = TrackingConfig.from_file(train_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done in child process to automatically free cuda resources\n",
    "p = multiprocessing.Process(target=train, args=(train_config,))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7369162",
   "metadata": {},
   "source": [
    "As training until convergence will take a while we provide a pretrained model that can be used to test the following steps of the tracking pipeline.\n",
    "To use the pretained model set `use_pretrained` to `True` and execute the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrained = False\n",
    "if use_pretrained:\n",
    "    !wget https://figshare.com/ndownloader/files/36939550 -nv -N --show-progress\n",
    "    shutil.copy2(\"36939550\", f\"train_net_checkpoint_{train_config.train.max_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c022b",
   "metadata": {},
   "source": [
    "Validation\n",
    "--------------\n",
    "\n",
    "After the training is completed we first have to determine the optimal ILP weights.\n",
    "This is achieved by first creating the prediction on the validation data and then performing a grid search by solving the ILP and evaluating the results repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_config_file = \"config_val.toml\"\n",
    "val_config = TrackingConfig.from_file(validation_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240c93",
   "metadata": {},
   "source": [
    "### Predict Validation Data\n",
    "\n",
    "First we predict the `cell_indicator` and `movement_vectors` on the validation data. Make sure that `inference_data` in the config file points to the data you want to use for validation. The extracted maxima of the `cell_indicator` map correspond to potential cells in our candidate graph.\n",
    "\n",
    "This command starts a number of workers (`predict.job.num_workers`) in the background, each worker tries to access a GPU. Do not start more workers than GPUs available. By default the workers are started locally. If you are working on a compute cluster (`lsf` supported, `slurm` and `gridengine` experimental) set `predict.job.run_on` to the respective string value, the code will communicate with the cluster scheduler and allocate the appropriate jobs.\n",
    "\n",
    "Depending on the number of workers used (see config file) and the size of the data this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9124e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba90ec2",
   "metadata": {},
   "source": [
    "### Extract Edges Validation Data\n",
    "\n",
    "In the next step we extract potential edges for our candidate graph. For each cell candidate, look for neighboring cells in the next time frame and insert an edge candidate for each into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_edges_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032f671",
   "metadata": {},
   "source": [
    "### ILP Weights Grid Search\n",
    "\n",
    "Cell/Node and edge candidates form together our candidate graph. By solving the ILP we extract tracks from this graph. However the ILP is parameterized by a set of weights. First we have to find the optimal values for these weights. To achieve this we perform a grid search over a predefined search space. For each set of parameter candidates we solve the ILP once on the validation data.\n",
    "\n",
    "#### Solve on Validation Data\n",
    "\n",
    "Make sure to provide a number of parameter sets (`solve.parameters`) to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fc5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linajea.process_blockwise.solve_blockwise(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a28d14",
   "metadata": {},
   "source": [
    "#### Evaluate on Validation Data\n",
    "\n",
    "And as a last validation step we evaluate the performance for each set of parameter candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_config_file = \"config_val.toml\"\n",
    "val_config = TrackingConfig.from_file(validation_config_file)\n",
    "parameters = val_config.solve.parameters\n",
    "for params in parameters:\n",
    "    val_config.solve.parameters = [params]\n",
    "    linajea.evaluation.evaluate_setup(val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4f46b",
   "metadata": {},
   "source": [
    "#### Determine best ILP weights\n",
    "\n",
    "The set of weights/parameters resulting in the best performance (fewest number of errors) will then be used to get the performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = ['fn_edges', 'identity_switches',\n",
    "                 'fp_divisions', 'fn_divisions']\n",
    "if not val_config.general.sparse:\n",
    "    score_columns = ['fp_edges'] + score_columns\n",
    "\n",
    "results = linajea.evaluation.get_results_sorted(\n",
    "    val_config,\n",
    "    filter_params={\"val\": True},\n",
    "    score_columns=score_columns,\n",
    "    sort_by=\"sum_errors\")\n",
    "\n",
    "parameters = val_config.solve.parameters[0]\n",
    "parameters.weight_node_score = float(results.iloc[0].weight_node_score)\n",
    "parameters.selection_constant = float(results.iloc[0].selection_constant)\n",
    "parameters.track_cost = float(results.iloc[0].track_cost)\n",
    "parameters.weight_edge_score = float(results.iloc[0].weight_edge_score)\n",
    "parameters.weight_division = float(results.iloc[0].weight_division)\n",
    "parameters.weight_child = float(results.iloc[0].weight_child)\n",
    "parameters.weight_continuation = float(results.iloc[0].weight_continuation)\n",
    "\n",
    "print(\"Best parameters:\\n\", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c155ee",
   "metadata": {},
   "source": [
    "Test\n",
    "------\n",
    "\n",
    "Now that we know which ILP weights to use we can create the candidate graph on the test data and compute the tracks. \n",
    "\n",
    "First load the test configuration file and set the parameters to the previously determined values (alternatively set the values manually directly in the configuration file). \n",
    "Make sure that `solve.grid_search` and `solve.random_search` are not set or set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dade09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config_file = \"config_test.toml\"\n",
    "test_config = TrackingConfig.from_file(test_config_file)\n",
    "test_config.solve.parameters = [parameters]\n",
    "test_config.solve.solver_type = val_config.solve.solver_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174b602",
   "metadata": {},
   "source": [
    "### Predict Test Data\n",
    "\n",
    "As before we first predict the `cell_indicator` and `movement_vectors`, this time on the test data. Make sure that `inference_data` in the config file points to the data you want to use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73142808",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a4f5c",
   "metadata": {},
   "source": [
    "### Extract Edges on Test Data\n",
    "\n",
    "In the next step we extract again the potential edges for our candidate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d995474",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_edges_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0660d",
   "metadata": {},
   "source": [
    "### Solve on Test Data\n",
    "\n",
    "Then we can solve the ILP on the test data and compute the tracks. Make sure that the ILP weights are set to the values that resulted in the lowest overall number of errors on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a141c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config.solve.from_scratch = True\n",
    "solve_blockwise(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448cb8d",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data\n",
    "\n",
    "And finally we can evaluate the performance of our tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03698bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = linajea.evaluation.evaluate_setup(test_config)\n",
    "for k, v in report.get_short_report().items():\n",
    "    print(f\"\\t{k: <32}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
