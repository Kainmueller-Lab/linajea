{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0754861b",
   "metadata": {},
   "source": [
    "Linajea Tracking Example\n",
    "=====================\n",
    "\n",
    "This example show all steps necessary to generate the final tracks, from training the network to finding the optimal ILP weights on the validation data to computing the tracks on the test data.\n",
    "\n",
    "- train network\n",
    "- predict on validation data\n",
    "- grid search weights for ILP\n",
    "  - solve once per set of weights\n",
    "  - evaluate once per set of weights\n",
    "  - select set with fewest errors\n",
    "- predict on test data\n",
    "- solve on test data with optimal weights\n",
    "- evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from linajea.config import (dump_config,\n",
    "                            maybe_fix_config_paths_to_machine_and_load,\n",
    "                            SolveParametersConfig,\n",
    "                            TrackingConfig)\n",
    "from linajea.utils import getNextInferenceData\n",
    "import linajea.evaluation\n",
    "from linajea.process_blockwise import (extract_edges_blockwise,\n",
    "                                       predict_blockwise,\n",
    "                                       solve_blockwise)\n",
    "from linajea.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(name)s %(levelname)-8s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2706",
   "metadata": {},
   "source": [
    "Configuration\n",
    "--------------------\n",
    "\n",
    "All parameters to control the pipeline (e.g. model architecture, data augmentation, training parameters, ILP weights) are contained in a configuration file (in the TOML format https://toml.io)\n",
    "\n",
    "You can use a single monolithic configuration file or separate configuration files for a subset of the steps of the pipeline, as long as the parameters required for the respective steps are there.\n",
    "\n",
    "Familiarize yourself with the example configuration files and have a look at the documentation for the configuration to see what is needed. Most parameters have sensible defaults; usually setting the correct paths and the data configuration is all that is needed to start. See `run_simple.ipynb` for a simpler example setup that can only handle one sample/volume per dataset and that requires manual selection of the data used in the individual steps.\n",
    "\n",
    "In this setup `train_data`, `val_data` and `test_data` have to be set once and depending on the processing step the correct data is selected automatically.\n",
    "\n",
    "Experiment\n",
    "-----------------\n",
    "\n",
    "To start a new experiment create a new folder and copy the configuration file(s) you want to use into this folder.\n",
    "Then modify the `config_file` variable to point to the config file. Make sure that the file paths contained in it point to the correct destination, for instance that they are adapted to your directory structure. And that `config.general.setup_dir` points to the folder you just created. \n",
    "To continue an existing experiment simply set `config_file` to point to the existing config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ca24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dir = \"example_advanced_1\"\n",
    "os.chdir(setup_dir)\n",
    "config_file = \"config_example_celegans.toml\"\n",
    "config = maybe_fix_config_paths_to_machine_and_load(config_file)\n",
    "config = TrackingConfig(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4a402",
   "metadata": {},
   "source": [
    "Training\n",
    "------------\n",
    "\n",
    "To start training simply pass the configuration object to the train function. Make sure that the training data and parameters such as the number of iterations/setps are set correctly.\n",
    "\n",
    "To train until convergence will take from several hours to multiple days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done in child process to automatically free cuda resources\n",
    "p = multiprocessing.Process(target=train, args=(config,))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c022b",
   "metadata": {},
   "source": [
    "Validation\n",
    "--------------\n",
    "\n",
    "After the training is completed we first have to determine the optimal ILP weights.\n",
    "This is achieved by first creating the prediction on the validation data and then performing a grid search by solving the ILP and evaluating the results repeatedly.\n",
    "\n",
    "`getNextInferenceData` can be used to loop over the samples in the respective dataset, it returns a generator.\n",
    "If `validation` is set to `True` in `args` the validation data is used, otherwise the test data. Other details (e.g. which training checkpoint to use, which database to store the results in to use) are determined automatically based on the configuration file. Internally it adds an `inference_data` entry that is used by the postprocessing functions such as `*_blockwise` and `evaluate_setup`. This entry is updated automatically after each iteration to point to the correct sample.\n",
    "\n",
    "MongoDB is used to store the computed results. A `mongod` server has to be running before executing the remaining cells.\n",
    "See https://www.mongodb.com/docs/manual/administration/install-community/ for a guide on how to install it (Linux/Windows/MacOS)\n",
    "Alternatively you might want to create a singularity image (https://github.com/singularityhub/mongo). This can be used locally but will be necessary if you want to run the code on an HPC cluster and there is no server installed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = types.SimpleNamespace(\n",
    "    config=config_file, validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240c93",
   "metadata": {},
   "source": [
    "### Predict Validation Data\n",
    "\n",
    "First we predict the `cell_indicator` and `movement_vectors` on the validation data. Make sure that `args.validation` is set to `True`, then execute the next cell. The extracted maxima of the `cell_indicator` map correspond to potential cells in our candidate graph.\n",
    "\n",
    "Depending on the number of workers used (see config file) and the size of the data this can take a while. If there is no progress for a while check the log files in `<setup_dir>/daisy_logs/linajea_prediction`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9124e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args.validation = True\n",
    "for inf_config in linajea.utils.getNextInferenceData(args):\n",
    "    predict_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba90ec2",
   "metadata": {},
   "source": [
    "### Extract Edges Validation Data\n",
    "\n",
    "In the next step we extract potential edges for our candidate graph. For each cell candidate, look for neighboring cells in the next time frame and insert an edge candidate for each into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inf_config in linajea.utils.getNextInferenceData(args):\n",
    "    extract_edges_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032f671",
   "metadata": {},
   "source": [
    "### ILP Weights Grid Search\n",
    "\n",
    "Cell/Node and edge candidates form together our candidate graph. By solving the ILP we extract tracks from this graph. However the ILP is parameterized by a set of weights. First we have to find the optimal values for these weights. To achieve this we perform a grid search over a predefined search space. For each set of parameter candidates we solve the ILP once on the validation data.\n",
    "\n",
    "\n",
    "#### Solve on Validation Data\n",
    "\n",
    "Make sure that `solve.grid_search` is set to `True`. The parameter sets to try are generated automatically based on the `solve.parameters_search_grid` settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.solve.grid_search = True\n",
    "config.solve.parameters = None\n",
    "args.config = dump_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fc5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(linajea.process_blockwise)\n",
    "importlib.reload(linajea.utils)\n",
    "\n",
    "parameters_ids = None\n",
    "for inf_config in linajea.utils.getNextInferenceData(args, is_solve=True):\n",
    "    parameters_ids = linajea.process_blockwise.solve_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a28d14",
   "metadata": {},
   "source": [
    "#### Evaluate on Validation Data\n",
    "\n",
    "And as a last validation step we evaluate the performance for each set of parameter candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(linajea.evaluation)\n",
    "importlib.reload(linajea.utils)\n",
    "\n",
    "args.param_ids = parameters_ids\n",
    "print(args.param_ids)\n",
    "for inf_config in linajea.utils.getNextInferenceData(args, is_evaluate=True):\n",
    "    linajea.evaluation.evaluate_setup(inf_config)\n",
    "    parameters = inf_config.solve.parameters[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427d9a7",
   "metadata": {},
   "source": [
    "#### Determine best ILP weights\n",
    "\n",
    "The set of weights/parameters resulting in the best performance (fewest number of errors) will then be used to get the performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.solve.grid_search = False\n",
    "config.solve.parameters = None\n",
    "args.param_ids = None\n",
    "args.config = dump_config(config)\n",
    "\n",
    "importlib.reload(linajea.utils)\n",
    "score_columns = ['fn_edges', 'identity_switches',\n",
    "                 'fp_divisions', 'fn_divisions']\n",
    "if not config.general.sparse:\n",
    "    score_columns = ['fp_edges'] + score_columns\n",
    "\n",
    "sort_by = \"sum_errors\"\n",
    "results = {}\n",
    "\n",
    "for sample_idx, inf_config in enumerate(linajea.utils.getNextInferenceData(args)):\n",
    "    sample = inf_config.inference_data.data_source.datafile.filename\n",
    "    print(\"getting results for:\", sample)\n",
    "    res = linajea.evaluation.get_results_sorted(\n",
    "        inf_config,\n",
    "        filter_params={\"val\": True},\n",
    "        score_columns=score_columns,\n",
    "        sort_by=sort_by)\n",
    "\n",
    "    results[os.path.basename(sample)] = res.reset_index()\n",
    "\n",
    "results = pd.concat(list(results.values())).reset_index()\n",
    "del results['param_id']\n",
    "del results['_id']\n",
    "\n",
    "by = [\n",
    "    \"matching_threshold\",\n",
    "    \"weight_node_score\",\n",
    "    \"selection_constant\",\n",
    "    \"track_cost\",\n",
    "    \"weight_division\",\n",
    "    \"division_constant\",\n",
    "    \"weight_child\",\n",
    "    \"weight_continuation\",\n",
    "    \"weight_edge_score\",\n",
    "]\n",
    "if \"cell_cycle_key\" in results:\n",
    "    by.append(\"cell_cycle_key\")\n",
    "\n",
    "results = results.groupby(by, dropna=False, as_index=False).agg(\n",
    "    lambda x: -1 if len(x) != sample_idx+1 else sum(x))\n",
    "\n",
    "results = results[results.sum_errors != -1]\n",
    "results.sort_values(sort_by, ascending=False, inplace=True)\n",
    "\n",
    "#parameters = SolveParametersConfig()\n",
    "parameters.weight_node_score = float(results.at[0, 'weight_node_score'])\n",
    "parameters.selection_constant = float(results.at[0, 'selection_constant'])\n",
    "parameters.track_cost = float(results.at[0, 'track_cost'])\n",
    "parameters.weight_edge_score = float(results.at[0, 'weight_edge_score'])\n",
    "parameters.weight_division = float(results.at[0, 'weight_division'])\n",
    "parameters.weight_child = float(results.at[0, 'weight_child'])\n",
    "parameters.weight_continuation = float(results.at[0, 'weight_continuation'])\n",
    "\n",
    "print(\"Best parameters:\\n\", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92993ea",
   "metadata": {},
   "source": [
    "Test\n",
    "------\n",
    "\n",
    "Now that we know which ILP weights to use we can create the candidate graph on the test data and compute the tracks. \n",
    "\n",
    "First load the test configuration file and set the parameters to the previously determined values (alternatively set the values manually directly in the configuration file). \n",
    "Make sure that `args.validation` is set to `False` and that `solve.grid_search` and `solve.random_search` are not set or set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.solve.parameters = [parameters]\n",
    "config.solve.grid_search = False\n",
    "config.solve.random_search = False\n",
    "args.config = dump_config(config)\n",
    "args.validation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174b602",
   "metadata": {},
   "source": [
    "### Predict Test Data\n",
    "\n",
    "Now that we know which ILP weights to use we can predict the `cell_indicator` and `movement_vectors` on the test data and compute the tracks. Make sure that `args.validation` is set to `False` and `solve.grid_search` and `solve.random_search` are set to `False`.\n",
    "If there is no progress for a while check the log files in `<setup_dir>/daisy_logs/linajea_prediction`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73142808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inf_config in linajea.utils.getNextInferenceData(args):\n",
    "    predict_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c29d00",
   "metadata": {},
   "source": [
    "### Extract Edges on Test Data\n",
    "\n",
    "In the next step we extract again the potential edges for our candidate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inf_config in linajea.utils.getNextInferenceData(args):\n",
    "    extract_edges_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0660d",
   "metadata": {},
   "source": [
    "### Solve on Test Data\n",
    "\n",
    "Then we can solve the ILP on the test data. We select the weights that resulted in the lowest overall number of errors on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a141c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inf_config in linajea.utils.getNextInferenceData(args, is_solve=True):\n",
    "    solve_blockwise(inf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448cb8d",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03698bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inf_config in linajea.utils.getNextInferenceData(args, is_evaluate=True):\n",
    "    report = linajea.evaluation.evaluate_setup(inf_config)\n",
    "    print(report.get_short_report())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:linajea_torch] *",
   "language": "python",
   "name": "conda-env-linajea_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
